{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b6181e2-f400-4d3f-912c-8d3421468404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9e1ef90-b7a4-4168-ae95-91d3e9beab9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bd120e-1b61-415b-b9e4-5bb7fc50087e",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f43ced6-38e2-4b16-bb39-89d3acb7028a",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (224,224)\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fda0a1-1768-4194-b32e-e0be583e2276",
   "metadata": {},
   "source": [
    "### Data Augmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f99b61ca-48ca-49b0-91d4-7e012bbd0098",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen =ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip =True\n",
    ")\n",
    "\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623e03c5-31cb-4741-9439-2f87aa657f1e",
   "metadata": {},
   "source": [
    "### Load train,test, validation Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8700b961-e596-4673-8ef7-cebb42a8101f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 155 images belonging to 3 classes.\n",
      "Found 33 images belonging to 3 classes.\n",
      "Found 36 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = train_datagen.flow_from_directory(\n",
    "    \"train\",\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_data = train_datagen.flow_from_directory(\n",
    "    \"val\",\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_data = train_datagen.flow_from_directory(\n",
    "    \"test\",\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5080b9ba-a3a9-43bb-97be-d308090cb425",
   "metadata": {},
   "source": [
    "### Building the model with InceptionV3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bca3ee5-a19e-49ca-aec5-eb8a25f42ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = InceptionV3(\n",
    "    weights = \"imagenet\",\n",
    "    include_top=False,\n",
    "    input_shape=(224,224,3)\n",
    ")\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a6df59-e7e0-4c1e-a552-59938c8f0994",
   "metadata": {},
   "source": [
    "### Adding custom Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2172b3f-13e6-42f3-a530-fdcc6e87ecd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(train_data.num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6e194f-5591-4188-bfb7-a30ecdf2122f",
   "metadata": {},
   "source": [
    "### Compilation of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61f4819c-b500-4e69-871e-6d1fd178c4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b76c497-1f62-40cb-8181-a4eb91c85c51",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95457cd6-9750-4c53-be51-f2251e982fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 6s/step - accuracy: 0.3161 - loss: 2.7662 - val_accuracy: 0.3636 - val_loss: 1.3284\n",
      "Epoch 2/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 4s/step - accuracy: 0.6129 - loss: 0.9219 - val_accuracy: 0.6667 - val_loss: 0.7235\n",
      "Epoch 3/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5s/step - accuracy: 0.6645 - loss: 0.7834 - val_accuracy: 0.8788 - val_loss: 0.4054\n",
      "Epoch 4/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4s/step - accuracy: 0.7935 - loss: 0.5476 - val_accuracy: 0.9394 - val_loss: 0.2831\n",
      "Epoch 5/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5s/step - accuracy: 0.8968 - loss: 0.3148 - val_accuracy: 0.6970 - val_loss: 0.6329\n",
      "Epoch 6/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 5s/step - accuracy: 0.8581 - loss: 0.2982 - val_accuracy: 0.9394 - val_loss: 0.2719\n",
      "Epoch 7/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 5s/step - accuracy: 0.9419 - loss: 0.2086 - val_accuracy: 1.0000 - val_loss: 0.1733\n",
      "Epoch 8/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 6s/step - accuracy: 0.9355 - loss: 0.1712 - val_accuracy: 0.8788 - val_loss: 0.2715\n",
      "Epoch 9/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5s/step - accuracy: 0.9613 - loss: 0.1178 - val_accuracy: 0.9697 - val_loss: 0.1733\n",
      "Epoch 10/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 6s/step - accuracy: 0.9677 - loss: 0.1406 - val_accuracy: 0.9091 - val_loss: 0.1971\n",
      "Epoch 11/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 4s/step - accuracy: 0.9613 - loss: 0.1013 - val_accuracy: 0.9394 - val_loss: 0.1802\n",
      "Epoch 12/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5s/step - accuracy: 0.9677 - loss: 0.0990 - val_accuracy: 0.9697 - val_loss: 0.1227\n",
      "Epoch 13/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 5s/step - accuracy: 0.9806 - loss: 0.0776 - val_accuracy: 1.0000 - val_loss: 0.0787\n",
      "Epoch 14/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 6s/step - accuracy: 0.9742 - loss: 0.0725 - val_accuracy: 1.0000 - val_loss: 0.0840\n",
      "Epoch 15/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 6s/step - accuracy: 0.9613 - loss: 0.0882 - val_accuracy: 1.0000 - val_loss: 0.1037\n",
      "Epoch 16/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 6s/step - accuracy: 0.9935 - loss: 0.0440 - val_accuracy: 0.9697 - val_loss: 0.0801\n",
      "Epoch 17/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 6s/step - accuracy: 0.9806 - loss: 0.0631 - val_accuracy: 0.9091 - val_loss: 0.1641\n",
      "Epoch 18/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 5s/step - accuracy: 0.9935 - loss: 0.0519 - val_accuracy: 0.9394 - val_loss: 0.1507\n",
      "Epoch 19/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 5s/step - accuracy: 0.9742 - loss: 0.0713 - val_accuracy: 0.9394 - val_loss: 0.1316\n",
      "Epoch 20/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5s/step - accuracy: 0.9935 - loss: 0.0506 - val_accuracy: 1.0000 - val_loss: 0.0654\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc263f3e-1524-435b-820d-dd234fca9664",
   "metadata": {},
   "source": [
    "### Unfreeze layers to finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72607823-c881-4816-bc6c-9ea7bef1f14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers[-50:]:\n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5ccc80-a8e1-4fff-bd93-390ddadb22eb",
   "metadata": {},
   "source": [
    "### Compile again with low learning rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e0f86a1-542a-4906-ba7c-42a5e39a4611",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-5),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7512a4-c1a5-4a0c-adc6-b400458f1466",
   "metadata": {},
   "source": [
    "### Train again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8cbc72c5-5c80-4cc5-8be7-65b20d2e6d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 7s/step - accuracy: 0.9355 - loss: 0.3393 - val_accuracy: 1.0000 - val_loss: 0.0872\n",
      "Epoch 2/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 6s/step - accuracy: 0.9419 - loss: 0.2625 - val_accuracy: 1.0000 - val_loss: 0.0540\n",
      "Epoch 3/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6s/step - accuracy: 0.9806 - loss: 0.1837 - val_accuracy: 1.0000 - val_loss: 0.0554\n",
      "Epoch 4/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7s/step - accuracy: 0.9677 - loss: 0.2436 - val_accuracy: 0.9697 - val_loss: 0.0532\n",
      "Epoch 5/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 7s/step - accuracy: 0.9677 - loss: 0.1880 - val_accuracy: 1.0000 - val_loss: 0.0359\n",
      "Epoch 6/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 7s/step - accuracy: 0.9742 - loss: 0.1881 - val_accuracy: 1.0000 - val_loss: 0.0536\n",
      "Epoch 7/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 7s/step - accuracy: 0.9806 - loss: 0.1741 - val_accuracy: 0.9394 - val_loss: 0.1309\n",
      "Epoch 8/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 6s/step - accuracy: 0.9871 - loss: 0.1425 - val_accuracy: 0.9394 - val_loss: 0.1309\n",
      "Epoch 9/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6s/step - accuracy: 0.9871 - loss: 0.1276 - val_accuracy: 1.0000 - val_loss: 0.0601\n",
      "Epoch 10/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 7s/step - accuracy: 0.9806 - loss: 0.1454 - val_accuracy: 1.0000 - val_loss: 0.0350\n"
     ]
    }
   ],
   "source": [
    "history_finetune = model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e03e771-c4bc-41a3-b27d-86a626dff7f5",
   "metadata": {},
   "source": [
    "## Evalutate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "270d9f3e-5540-48b9-85b4-e0c5da9281e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 361ms/step - accuracy: 0.9722 - loss: 0.0511\n",
      "Test Accuracy: 0.9722222089767456\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_data)\n",
    "print('Test Accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c756b1cd-c61f-47c1-a202-c7a28557087e",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e8bba17e-fdb2-4052-b9c3-cf4d05164a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3332f8f6-f580-4af6-9c50-94b9399848a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        12\n",
      "           1       1.00      1.00      1.00        12\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_probs = model.predict(test_data)\n",
    "pred_classes = np.argmax(pred_probs, axis=1)\n",
    "true_classes = test_data.classes\n",
    "\n",
    "print(classification_report(true_classes, pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "735c4702-27eb-4649-8afc-ef326d51c8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"plant_disease_inceptionV3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cda37c-68ad-43de-8dec-fb17de120e42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
